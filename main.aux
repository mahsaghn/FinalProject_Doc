\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\providecommand*\new@tpo@label[2]{}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\citation{Hierarchical-Attention-Network}
\citation{stance_persian}
\citation{stance_persian}
\citation{stance_persian}
\citation{parsfever}
\citation{stance_persian}
\citation{parsbert}
\citation{parsbert}
\citation{albert}
\citation{stance_persian}
\citation{stance_persian}
\citation{adasyn}
\citation{memory_network}
\citation{UCLMR}
\citation{UCLMR}
\citation{takestancefake}
\citation{book_fake}
\citation{takestancefake}
\citation{stance_robust}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{15}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{stanceCI}
\citation{stanceCI}
\citation{memory_network}
\citation{stance_robust}
\citation{book_datafake}
\citation{bert}
\citation{bert}
\citation{bert}
\citation{spotfake}
\citation{book_datafake}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{17}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}BERT}{17}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}ALBERT}{18}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}ParsBERT}{18}{section.2.3}\protected@file@percent }
\citation{Augenstein2016StanceDW}
\citation{Augenstein2016StanceDW}
\citation{Augenstein2016StanceDW}
\citation{svc}
\citation{bow}
\citation{UCLMR}
\citation{sikit-learn}
\citation{UCLMR}
\citation{UCLMR}
\citation{Hierarchical-Attention-Network}
\citation{Hierarchical-Attention-Network}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Works}{19}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{literature}{{3}{19}{Related Works}{chapter.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Schematic diagram of UCLMR’s system.\relax }}{20}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:UCLMR-system}{{3.1}{20}{Schematic diagram of UCLMR’s system.\relax }{figure.caption.5}{}}
\citation{Hierarchical-Attention-Network}
\citation{Hierarchical-Attention-Network}
\citation{Hierarchical-Attention-Network}
\citation{Hierarchical-Attention-Network}
\citation{Hierarchical-Attention-Network}
\citation{memory_network}
\citation{memory_network}
\citation{memory_network}
\citation{stance_robust}
\citation{bert}
\citation{stance_robust}
\citation{stance_robust}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Overview of \cite  {Hierarchical-Attention-Network} model.\relax }}{22}{figure.caption.6}\protected@file@percent }
\newlabel{fig:hierarchical_att}{{3.2}{22}{Overview of \cite {Hierarchical-Attention-Network} model.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of Memory Network for stance detection.\relax }}{22}{figure.caption.7}\protected@file@percent }
\newlabel{fig:mem_network}{{3.3}{22}{Architecture of Memory Network for stance detection.\relax }{figure.caption.7}{}}
\citation{stance_persian}
\citation{stance_persian}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Dataset}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:dataset}{{4}{25}{Dataset}{chapter.4}{}}
\citation{stance_persian}
\citation{stance_persian}
\citation{stance_persian}
\citation{stance_persian}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Stance class distribution\relax }}{26}{table.caption.8}\protected@file@percent }
\newlabel{tbl:sdatapie}{{4.1}{26}{Stance class distribution\relax }{table.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Comparison between Article to claim and Headline to claim labels, samples distribution in \cite  {stance_persian} dataset.\relax }}{26}{figure.caption.9}\protected@file@percent }
\newlabel{fig:datacom}{{4.1}{26}{Comparison between Article to claim and Headline to claim labels, samples distribution in \cite {stance_persian} dataset.\relax }{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Fake news data set statistics\relax }}{27}{table.caption.10}\protected@file@percent }
\newlabel{fake-news-dataset}{{4.2}{27}{Fake news data set statistics\relax }{table.caption.10}{}}
\newlabel{tbl:fakedata}{{4.2}{27}{Fake news data set statistics\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Claim veracity label's distribution in \cite  {stance_persian} dataset.\relax }}{27}{figure.caption.11}\protected@file@percent }
\newlabel{fig:fake}{{4.2}{27}{Claim veracity label's distribution in \cite {stance_persian} dataset.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments}{29}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:exp}{{5}{29}{Experiments}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Preprocessing}{29}{section.5.1}\protected@file@percent }
\newlabel{fn:hazm}{{1}{29}{Preprocessing}{section.5.1}{}}
\citation{bert}
\citation{stance_persian}
\citation{bow}
\citation{tfidf}
\citation{word2vec}
\citation{bow}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Word Representation}{30}{section.5.2}\protected@file@percent }
\newlabel{fn:kharazi}{{6}{30}{Preprocessing}{section.5.1}{}}
\citation{tfidf}
\citation{word2vec}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}BoW\footnote {en.wikipedia.org/Bag-of-words\_model}}{31}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}TF-IDF}{31}{subsection.5.2.2}\protected@file@percent }
\newlabel{eq:tf}{{5.1}{31}{TF-IDF}{equation.5.2.1}{}}
\newlabel{idf}{{5.2}{31}{TF-IDF}{equation.5.2.2}{}}
\newlabel{tfidf}{{5.3}{31}{TF-IDF}{equation.5.2.3}{}}
\citation{stance_persian}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}W2V\footnote {en.wikipedia.org/wiki/Word2vec}}{32}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Features}{32}{section.5.3}\protected@file@percent }
\newlabel{sec:features}{{5.3}{32}{Features}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Similarity}{32}{subsection.5.3.1}\protected@file@percent }
\newlabel{eq_ratio}{{5.4}{32}{Similarity}{equation.5.3.4}{}}
\citation{stance_persian}
\citation{stance_persian}
\citation{stance_persian}
\citation{stance_persian}
\citation{persent}
\citation{persent}
\citation{persent}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Root Distance}{33}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}ImportantWords}{33}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Is Question}{33}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Has Two Parts}{33}{subsection.5.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Polarity}{33}{subsection.5.3.6}\protected@file@percent }
\citation{persent}
\citation{persent}
\citation{persent}
\citation{polar_hotel}
\citation{polar_servic}
\citation{book_fake}
\citation{book_fake}
\newlabel{eq_polar}{{5.5}{34}{Polarity}{equation.5.3.5}{}}
\citation{GNbayes}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Schematic of each machine learning model.\relax }}{35}{figure.caption.12}\protected@file@percent }
\newlabel{fig:mlschm}{{5.1}{35}{Schematic of each machine learning model.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Machine Learning}{35}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Gaussian Naive Bayes}{35}{subsection.5.4.1}\protected@file@percent }
\citation{svc}
\citation{randomforest}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}SVC\footnote {wikipedia.org/Support-vector\_machine}}{36}{subsection.5.4.2}\protected@file@percent }
\newlabel{SVM}{{5.4.2}{36}{SVC\protect \footnote {wikipedia.org/Support-vector\_machine}}{subsection.5.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}LinearSVC}{36}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Random Forest}{37}{subsection.5.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Logistic Regression}{37}{subsection.5.4.5}\protected@file@percent }
\newlabel{eq:logil}{{5.6}{37}{Logistic Regression}{equation.5.4.6}{}}
\newlabel{eq:logill}{{5.7}{37}{Logistic Regression}{equation.5.4.7}{}}
\newlabel{eq:logisel}{{5.8}{37}{Logistic Regression}{equation.5.4.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Balancing}{38}{section.5.5}\protected@file@percent }
\newlabel{eq:acc}{{5.9}{38}{Balancing}{equation.5.5.9}{}}
\newlabel{eq:f1}{{5.10}{38}{Balancing}{equation.5.5.10}{}}
\citation{stance_persian}
\citation{parsfever}
\citation{fever}
\citation{parsfever}
\citation{stance_persian}
\citation{parsfever}
\citation{stance_persian}
\citation{stance_persian}
\citation{parsfever}
\citation{stance_persian}
\citation{parsfever}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Extending dataset}{39}{subsection.5.5.1}\protected@file@percent }
\citation{smothe}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Comparison between Article to claim and Headline to claim labels, samples distribution in \cite  {stance_persian} dataset, after extending by \cite  {parsfever} .\relax }}{40}{figure.caption.13}\protected@file@percent }
\newlabel{fig:datab1}{{5.2}{40}{Comparison between Article to claim and Headline to claim labels, samples distribution in \cite {stance_persian} dataset, after extending by \cite {parsfever} .\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Oversampling and Undersampling}{40}{subsection.5.5.2}\protected@file@percent }
\citation{svmsmothe}
\citation{svmsmothe}
\citation{borderlinesmothe}
\citation{borderlinesmothe}
\citation{adasyn}
\citation{adasyn}
\citation{book_datafake}
\citation{book_fake}
\citation{stance_robust}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Tune mode parameters}{41}{subsection.5.5.3}\protected@file@percent }
\citation{parsbert}
\citation{bert}
\citation{albert}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Schematic of each deep learning model.\relax }}{42}{figure.caption.14}\protected@file@percent }
\newlabel{fig:dlschm}{{5.3}{42}{Schematic of each deep learning model.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Deep Learning}{42}{section.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}BERT}{42}{subsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}ALBERT}{42}{subsection.5.6.2}\protected@file@percent }
\citation{stance_persian}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Schematic of each fake news detection model.\relax }}{43}{figure.caption.15}\protected@file@percent }
\newlabel{fig:fnschm}{{5.4}{43}{Schematic of each fake news detection model.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Article to Claim}{43}{section.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Fake News Detection}{43}{section.5.8}\protected@file@percent }
\newlabel{sec:fakenews}{{5.8}{43}{Fake News Detection}{section.5.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Value of credibility according to GroundTruth and Veracity labels. \relax }}{44}{table.caption.16}\protected@file@percent }
\newlabel{tbl:cred}{{5.1}{44}{Value of credibility according to GroundTruth and Veracity labels. \relax }{table.caption.16}{}}
\newlabel{eq:cred}{{5.11}{44}{Fake News Detection}{equation.5.8.11}{}}
\newlabel{eq:honesty}{{5.12}{44}{Fake News Detection}{equation.5.8.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results}{47}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapter:four}{{6}{47}{Results}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Tokenizetion}{47}{section.6.1}\protected@file@percent }
\citation{stance_persian}
\citation{stance_persian}
\citation{stance_persian}
\citation{svc}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Comparison performance of \textit  {Hazm}, \textit  {Stanford}, \textit  {NLTK} and \textit  {BERT} tokenizers.\relax }}{48}{figure.caption.17}\protected@file@percent }
\newlabel{fig:tekenres}{{6.1}{48}{Comparison performance of \textit {Hazm}, \textit {Stanford}, \textit {NLTK} and \textit {BERT} tokenizers.\relax }{figure.caption.17}{}}
\citation{stance_persian}
\citation{bow}
\citation{word2vec}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Comparison duration of tokenizing algorithm on \cite  {stance_persian} dataset.\relax }}{49}{figure.caption.18}\protected@file@percent }
\newlabel{fig:tokentime}{{6.2}{49}{Comparison duration of tokenizing algorithm on \cite {stance_persian} dataset.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Stop-Words}{49}{section.6.2}\protected@file@percent }
\citation{svc}
\citation{randomforest}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Comparison accuracy of SVM model with different configuration of stop words.\relax }}{50}{figure.caption.19}\protected@file@percent }
\newlabel{fig:stopwords}{{6.3}{50}{Comparison accuracy of SVM model with different configuration of stop words.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Word Representation}{50}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Predictors}{50}{section.6.4}\protected@file@percent }
\newlabel{sec:predictors}{{6.4}{50}{Predictors}{section.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Comparison SVM model with Bow, TF-iDF and Word2Vec word representaion algorithms.\relax }}{51}{figure.caption.20}\protected@file@percent }
\newlabel{fig:wordrep}{{6.4}{51}{Comparison SVM model with Bow, TF-iDF and Word2Vec word representaion algorithms.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Machine Learning}{51}{section.6.5}\protected@file@percent }
\newlabel{sec:ml}{{6.5}{51}{Machine Learning}{section.6.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Comparison of accuracy and F1-score with different combinations of predictors for both SVM and Random Forest classifiers.\relax }}{52}{table.caption.21}\protected@file@percent }
\newlabel{tlb:predictors}{{6.1}{52}{Comparison of accuracy and F1-score with different combinations of predictors for both SVM and Random Forest classifiers.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}SVM}{52}{subsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.2}Linear SVC}{52}{subsection.6.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Tuning SVM model parameters with TF-iDF representaion algorithms\relax }}{53}{figure.caption.22}\protected@file@percent }
\newlabel{fig:svm}{{6.5}{53}{Tuning SVM model parameters with TF-iDF representaion algorithms\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.3}Random Forest}{53}{subsection.6.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Tuning LinearSVC model parameters with TF-iDF representaion algorithms.\relax }}{54}{figure.caption.23}\protected@file@percent }
\newlabel{fig:linearsvm}{{6.6}{54}{Tuning LinearSVC model parameters with TF-iDF representaion algorithms.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.4}Logistic Regression}{54}{subsection.6.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Random Forest machine learning model different configuration on stance detection task. Type of line presents type of boundary applied on each model. Solid line, dash line and doted line stands for no boundary, sqrt of total feature and log2 of total feature respectively.\relax }}{55}{figure.caption.24}\protected@file@percent }
\newlabel{fig:randomforest}{{6.7}{55}{Random Forest machine learning model different configuration on stance detection task. Type of line presents type of boundary applied on each model. Solid line, dash line and doted line stands for no boundary, sqrt of total feature and log2 of total feature respectively.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Effect of $\rho $ parameter of \textit  {elasticnet} penalty on stance detection task.\relax }}{55}{figure.caption.25}\protected@file@percent }
\newlabel{fig:logistic1}{{6.8}{55}{Effect of $\rho $ parameter of \textit {elasticnet} penalty on stance detection task.\relax }{figure.caption.25}{}}
\citation{stance_persian}
\citation{stance_persian}
\citation{parsfever}
\citation{stance_persian}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Effect of regression parameter of \textit  {elasticnet} penalty on stance detection task.\relax }}{56}{figure.caption.26}\protected@file@percent }
\newlabel{fig:logistic2}{{6.9}{56}{Effect of regression parameter of \textit {elasticnet} penalty on stance detection task.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.5}Comparison}{56}{subsection.6.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Dataset Balancing}{56}{section.6.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces \relax }}{57}{figure.caption.27}\protected@file@percent }
\newlabel{fig:logistic3}{{6.10}{57}{\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Comparison SVM model with Bow, TF-iDF and Word2Vec word representation algorithms.\relax }}{57}{figure.caption.28}\protected@file@percent }
\newlabel{fig:all}{{6.11}{57}{Comparison SVM model with Bow, TF-iDF and Word2Vec word representation algorithms.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Comparison SVM model with Bow, TF-iDF and Word2Vec word representation algorithms.\relax }}{58}{figure.caption.29}\protected@file@percent }
\newlabel{fig:balanc}{{6.12}{58}{Comparison SVM model with Bow, TF-iDF and Word2Vec word representation algorithms.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Deep Learning}{58}{section.6.7}\protected@file@percent }
\newlabel{sec:dl}{{6.7}{58}{Deep Learning}{section.6.7}{}}
\citation{parsbert}
\citation{parsbert}
\citation{albert}
\citation{parsbert}
\citation{parsbert}
\citation{albert}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces comparison of headline-to-claim stance detection models.\relax }}{59}{table.caption.31}\protected@file@percent }
\newlabel{tbl:allstance}{{6.2}{59}{comparison of headline-to-claim stance detection models.\relax }{table.caption.31}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Comparison of article-to-claim machine learning and deep learning models.\relax }}{59}{table.caption.32}\protected@file@percent }
\newlabel{tbl:allstance}{{6.3}{59}{Comparison of article-to-claim machine learning and deep learning models.\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Article to Claim}{59}{section.6.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces Deep learning procedure on the headline-to-claim stance detection task. Left figures illustrate loss score and right figures illustrate accuracy score of train and test data during training procedure. (a, b) Pre-trained language model based on Google's BERT (\cite  {parsbert}) on Persian corpus (c, d) Pre-trained monolingual language model based on ParsBERT (\cite  {parsbert}) on Persian corpus. (e, f) Pre-trained language model based on ALBERT (\cite  {albert}) on Persian corpus\relax }}{60}{figure.caption.30}\protected@file@percent }
\newlabel{fig:deep}{{6.13}{60}{Deep learning procedure on the headline-to-claim stance detection task. Left figures illustrate loss score and right figures illustrate accuracy score of train and test data during training procedure. (a, b) Pre-trained language model based on Google's BERT (\cite {parsbert}) on Persian corpus (c, d) Pre-trained monolingual language model based on ParsBERT (\cite {parsbert}) on Persian corpus. (e, f) Pre-trained language model based on ALBERT (\cite {albert}) on Persian corpus\relax }{figure.caption.30}{}}
\citation{stance_persian}
\citation{stance_persian}
\citation{adasyn}
\citation{stance_persian}
\citation{stance_persian}
\citation{adasyn}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Left figures illustrate loss score and right figures illustrate accuracy score of train and test data during training procedure for each iteration. (a, b) Training procdure on fake news detection model trained on the \cite  {stance_persian} dataset. (c, d) Training procdure on fake news detection model trained on oversampled \cite  {stance_persian} dataset by ADASYN (\cite  {adasyn}) algorithm.\relax }}{61}{figure.caption.33}\protected@file@percent }
\newlabel{fig:fakenews}{{6.14}{61}{Left figures illustrate loss score and right figures illustrate accuracy score of train and test data during training procedure for each iteration. (a, b) Training procdure on fake news detection model trained on the \cite {stance_persian} dataset. (c, d) Training procdure on fake news detection model trained on oversampled \cite {stance_persian} dataset by ADASYN (\cite {adasyn}) algorithm.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Fake News}{61}{section.6.9}\protected@file@percent }
\citation{stance_persian}
\citation{parsbert}
\citation{book_fake}
\citation{stance_persian}
\citation{stance_persian}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{63}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{book_disinformation}
\citation{stance_persian}
\bibdata{main.bib}
\bibcite{Augenstein2016StanceDW}{{1}{2016}{{Augenstein et~al.}}{{Augenstein, Rockt{\"a}schel, Vlachos, and Bontcheva}}}
\bibcite{svc}{{2}{2011}{{Chang and Lin}}{{}}}
\bibcite{smothe}{{3}{2002}{{Chawla et~al.}}{{Chawla, Bowyer, Hall, and Kegelmeyer}}}
\bibcite{persent}{{4}{2016}{{Dashtipour et~al.}}{{Dashtipour, Hussain, Zhou, Gelbukh, Hawalah, and Cambria}}}
\bibcite{book_datafake}{{5}{2021}{{Deepak~P}}{{}}}
\bibcite{polar_hotel}{{6}{2019}{{Dehkharghani}}{{}}}
\bibcite{bert}{{7}{2019}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\bibcite{takestancefake}{{8}{2019}{{Dulhanty et~al.}}{{Dulhanty, Deglint, Ben~Daya, and Wong}}}
\bibcite{sikit-learn}{{9}{2011}{{F.~Pedregosa and Duchesnay.}}{{}}}
\bibcite{parsbert}{{10}{2020}{{Farahani et~al.}}{{Farahani, Gharachorloo, Farahani, and Manthouri}}}
\bibcite{book_fake}{{11}{2021}{{Giansiracusa}}{{}}}
\bibcite{borderlinesmothe}{{12}{2005}{{Han et~al.}}{{Han, Wang, and Mao}}}
\bibcite{bow}{{13}{1954}{{Harris}}{{}}}
\bibcite{adasyn}{{14}{2008}{{He et~al.}}{{He, Bai, Garcia, and Li}}}
\bibcite{GNbayes}{{15}{1995}{{John and Langley}}{{}}}
\bibcite{albert}{{16}{2020}{{Lan et~al.}}{{Lan, Chen, Goodman, Gimpel, Sharma, and Soricut}}}
\bibcite{randomforest}{{17}{2002}{{Liaw and Wiener}}{{}}}
\bibcite{stance_persian}{{18}{2019}{{Majid~Zarharan}}{{}}}
\bibcite{polar_servic}{{19}{2020}{{Mehrdad~Farahani}}{{}}}
\bibcite{memory_network}{{20}{2018}{{Mohtarami et~al.}}{{Mohtarami, Baly, Glass, Nakov, M{\`a}rquez, and Moschitti}}}
\bibcite{stanceCI}{{21}{2017}{{Mrowca et~al.}}{{Mrowca, Wang, and Kosson}}}
\bibcite{UCLMR}{{22}{2017}{{Riedel et~al.}}{{Riedel, Augenstein, Spithourakis, and Riedel}}}
\bibcite{tfidf}{{23}{2010}{{Sammut and Webb}}{{}}}
\bibcite{stance_robust}{{24}{2020}{{Schiller et~al.}}{{Schiller, Daxenberger, and Gurevych}}}
\bibcite{book_disinformation}{{25}{2020}{{Shu et~al.}}{{Shu, Wang, Lee, and Liu}}}
\bibcite{spotfake}{{26}{2019}{{Singhal et~al.}}{{Singhal, Shah, Chakraborty, Kumaraguru, and Satoh}}}
\bibcite{Hierarchical-Attention-Network}{{27}{2018}{{Sun et~al.}}{{Sun, Wang, Zhu, and Zhou}}}
\bibcite{fever}{{28}{2018}{{Thorne et~al.}}{{Thorne, Vlachos, Christodoulopoulos, and Mittal}}}
\bibcite{word2vec}{{29}{2013}{{Tomas~Mikolov}}{{}}}
\bibcite{svmsmothe}{{30}{2003}{{Wu and Chang}}{{}}}
\bibcite{parsfever}{{31}{2021}{{Zarharan et~al.}}{{Zarharan, Ghaderan, Pourdabiri, Sayedi, Minaei-Bidgoli, Eetemadi, and Pilehvar}}}
\bibstyle{acl_natbib}
