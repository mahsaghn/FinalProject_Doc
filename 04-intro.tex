These days, fake news and false information have been vastly flooding the Internet by numerous not verified news agencies with aims ranging from affecting individual people’s beliefs or decisions to influencing momentous events such as political elections (\cite{memory_network}). As days go by, the importance of automatically detecting stance is attracting more attention. Insofar as it has been suggested that automatic stance detection is the first step towards assisting human fact-checkers to detect inaccurate claims \cite{UCLMR}.


%these notions by Claire Wardle from First Draft, 2 misinformation is “unintentional mistakes such as inaccurate photo captions, dates, statistics, translations, or when satire is taken seriously.”, and disinformation is “fabricated or deliberately manipulated audio/visual context, and also intentionally created conspiracy theories or rumours.”.\cite{stace_survey}

The purpose of automatic stance detection is to classify the relationship between a claim and a given text. Four considered labels are \textit{Agree}, \textit{Disagreed}, \textit{Discussed}, and \textit{Not Enough Information}. So it is possible to evaluate the orientation of a news source towards a particular issue \cite{UCLMR}. The claim could be a sentence, a news item, an idea, a social network post, or any other source. Also, the text could be retrieved from news agencies, weblogs, posts that are shared on social media, or any available information. Choosing the source and context of the sentence and the text depends on the goal of the defined task. 

Gathering sufficient amount of data is a vital step to achieve a reliable predictor model. Both numbers of records in the dataset and the quality of each sample have a noticeable effect on stance prediction accuracy. \cite{takestancefake}) gathered fifty thousand article-headline pairs for their dataset, and achieved a respectable ninety percent accuracy, which was considerably higher than previous attempts by other researchers (\cite{book_fake}). Though, there is not enough available data in some contexts. Here is where transfer learning methods play a key role and compensate lack of data. \cite{stance_robust} improved stance detection model accuracy by fine-tuning \ac{BERT} model.
Also, \cite{takestancefake} used RoBERTa model which is pre-trained on Facebook data. Then fine-tune it on the specified current task. In this project, we adopted a pre-trained model on a large text corpus in a general context and then fine-tune the model on task-specified data.

Researchers have suggested various methods for stance classification. One cluster of methods mainly focuses on deep learning approaches. The precision of models is improved by using word embeddings such as using recurrent neural networks such as LSTM and BiLSTM (\cite{stanceCI}), \ac{BERT}, and utilizing attention-based networks (\cite{stanceCI}). Besides, \cite{memory_network} currently proposed a novel model architecture based on memory networks.

One possible way of judging the veracity of a given claim is detecting the stance of that claim against available trusted sources. The stance detection task traditionally was used in political and ideological debates fields \citep{stance_robust}. The idea of using Stance Detection techniques to analyze news item's correctness has become caught researcher's attention since 2016. Consistency of a sentence through sources can be retrieved by stance detection methods. Consequently, stance detection can be considered a subtask of the fake news detection task (\cite{book_datafake}), and It is easier to judge  the veracity of a claim by its stance against other sources. Thus, classifying the stance of a particular claim towards available documents is the first step in detecting fake news in this project. 
